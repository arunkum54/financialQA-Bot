# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WvJZ_dbd7Se5WJ329CoQJKX3vwK1L1AE
"""

# Run this cell first to install dependencies
!pip install openai
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install transformers sentence-transformers pinecone-client pdfplumber pytesseract pdf2image pillow python-dateutil
!pip install pytesseract pdfplumber pdf2image pillow
!apt-get install poppler-utils -qq
!pip install pdf2image pytesseract -q

# IMPORTING LIBRARIES
import pdfplumber
import pinecone
import torch
import re
import json
import pytesseract
import os
import pandas as pd
from PIL import Image
from datetime import datetime
from dateutil.parser import parse
from pdf2image import convert_from_path
from sentence_transformers import SentenceTransformer
from transformers import T5Tokenizer, T5ForConditionalGeneration
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Text extracting with OCR fallback to pdfplumber
def extract_text_from_pdf(pdf_path):
    extracted_text = []

    try:
        images = convert_from_path(pdf_path) # To Convert PDF to images

        for i, image in enumerate(images): # first Trying OCR extraction
            page_text = pytesseract.image_to_string(image)

            # if and only OCR extraction failed
            if not page_text.strip() or len(page_text) < 50:
                # then Fallback to pdfplumber
                with pdfplumber.open(pdf_path) as pdf:
                    page = pdf.pages[i]
                    page_text = page.extract_text() or ""

            extracted_text.append(page_text)
    except Exception as e:
        print(f"Error in OCR processing: {e}")
        with pdfplumber.open(pdf_path) as pdf:
            extracted_text = [page.extract_text() or "" for page in pdf.pages]

    return "\n".join(extracted_text)

# Structuring extracted text into key-value pairs and tables
def structure_extracted_text(text):
    structured_data = []
    current_table = []
    in_table = False

    for line in text.split("\n"):
        # To Table detection
        if re.match(r"(\s{2,}.+){2,}", line) or "|" in line:
            if not in_table:
                in_table = True
                current_table = []
            # Cleaning and split table row
            row = [cell.strip() for cell in re.split(r"\s{2,}|\|", line) if cell.strip()]
            current_table.append(row)
        else:
            if in_table:
                structured_data.append({"table": current_table})
                current_table = []
                in_table = False

            # Key-value detection
            kv_match = re.match(r"^(.+?):\s*(.+)$", line)
            if kv_match:
                key = kv_match.group(1).strip()
                value = kv_match.group(2).strip()
                structured_data.append({key: value})
            elif line.strip():
                structured_data.append({"text": line.strip()})

    if in_table and current_table:
        structured_data.append({"table": current_table})

    return structured_data

# Defining multiple chunking strategies
def chunk_structured_data(structured_data, chunk_size=1000, overlap=296):
    # Converting structured data to text for chunking (unchanged)
    text_representation = []
    for item in structured_data:
        if "table" in item:
            table_text = "\n".join([", ".join(row) for row in item["table"]])
            text_representation.append(f"Table:\n{table_text}")
        elif "text" in item:
            text_representation.append(item["text"])
        else:
            for key, value in item.items():
                text_representation.append(f"{key}: {value}")
    full_text = "\n".join(text_representation)

    # Initializing text splitter
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=overlap,
        separators=["\n\n", "\n", "|"],
        length_function=len
    )

    # Split and add metadata
    chunks = text_splitter.split_text(full_text)
    return [{
        "text": chunk,
        "chunk_size": chunk_size,
        "overlap": overlap
    } for chunk in chunks]

pdf_path = "/content/Sample Financial Statement.pdf"

# To Extract text calling funtion
raw_text = extract_text_from_pdf(pdf_path)
print(raw_text)

# To make text to structured one calling funtion
structured_data = structure_extracted_text(raw_text)
print(structured_data)

#To create chucks for better understanding for LLM and Memory
data_chunks = chunk_structured_data(structured_data)
print(f"Extracted {len(data_chunks)} chunks:")
for i, chunk in enumerate(data_chunks):
    print(f"\nChunk {i+1}:\n{chunk[:200]}...")

# Generating chunks with different strategies so that the LLM can get best one chuck and understand particular context properly
small_chunks = chunk_structured_data(structured_data, chunk_size=906, overlap=380)
medium_chunks = chunk_structured_data(structured_data, chunk_size=960, overlap=412)
large_chunks = chunk_structured_data(structured_data, chunk_size=1005, overlap=501)

# Combining all chunks
all_chunks = small_chunks + large_chunks
for i , chuck in enumerate(all_chunks):
  print(f"\nChunk {i+1}:\n{chunk[:200]}...")

from pinecone import Pinecone, ServerlessSpec

def init_pinecone_index(api_key, index_name="testin"): # Here i have testin index if you want to use then create testin or change the name as your preferens
    pc = Pinecone(api_key=api_key)

    # Checking if index exists
    if index_name not in pc.list_indexes().names():
        pc.create_index(
            name=index_name,
            dimension=384,
            metric="cosine",
            spec=ServerlessSpec(
                cloud="aws",
                region="us-east-1"
            )
        )

    return pc.Index(index_name)

from sentence_transformers import SentenceTransformer
from pinecone import Pinecone, ServerlessSpec
import os

# Initializing Pinecone with correct configuration
def init_pinecone_index(api_key):
    pc = Pinecone(api_key=api_key)

    # Checking if index exists, create if not
    index_name = "testin"
    if index_name not in pc.list_indexes().names():
        pc.create_index(
            name=index_name,
            dimension=384,  # Must match 'all-MiniLM-L6-v2' embeddingg/ while creating index in pinecone , the dimention should be exact same
            metric="cosine",
            spec=ServerlessSpec(
                cloud="aws",
                region="us-west-2"
            )
        )
    return pc.Index(index_name)

# Initializing with your API key
pinecone_api_key = "pcsk_utwYR_C7q4xZxvhh32bgHuBHYVGDA4XYZPCr9dgpb64mHx3gKRvLLfArTTZnqL6uKNea8"
index = init_pinecone_index(pinecone_api_key)

# Initialize embedding model
embedder = SentenceTransformer('all-MiniLM-L6-v2')  #  this has Dimension=384

batch_size = 10
for i in range(0, len(all_chunks), batch_size):
    batch = all_chunks[i:i + batch_size]
    vectors = []

    for j, chunk in enumerate(batch):
        # Generating embedding
        embedding = embedder.encode(chunk).tolist()
        truncated_text = chunk[:2000]  # Keep first 2000 characters

        vectors.append({
            "id": f"chunk_{i + j}",  # this is Unique string ID
            "values": embedding,      # Embedding vector
            "metadata": {             # Must be <40KB
                "text": truncated_text
            }
        })

    # Upserting into pinecone with error handling
    try:
        index.upsert(vectors=vectors)
        print(f"Upserted batch {i//batch_size + 1}")
    except Exception as e:
        print(f"Failed batch {i//batch_size + 1}: {str(e)}")

!pip install openai
import openai
from openai import OpenAI
#Use your API  or if you are testing my code then do not use much because i have very less limit , sorry for this.
client = OpenAI(api_key="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")

def generate_response(query, index):
    # Retrieving relevant chunks
    query_embedding = embedder.encode(query).tolist()
    results = index.query(
        vector=query_embedding,
        top_k=5,  # Retrieve top 5 relevant chunks
        include_metadata=True
    )
    # Extracting context from the results
    context = [m.metadata['text'] for m in results.matches]
    # Creating prompt
    prompt = f"""Answer the financial question using only this context:
    {chr(10).join(context)}

    Question: {query}
    Answer:"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant that provides accurate financial information based on the given context."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=200,
        temperature=0.7
    )

    return response.choices[0].message.content

queries = [
    "What is the total revenue for the year 2024?",
    "What is the gross profit for Q3 2024?",
    "What were the expenses on employee benefits for 2024?",
    "What is the comparison between net income and operating expenses for 2024?",
    "What is the value of goodwill as of March 31, 2024?",
    "What are the key components of current liabilities?",
    "What is the total equity as of March 31, 2024?",
    "What is the total revenue for the year ending March 31, 2024?",
    "What is the net profit reported for the same period?",
    "How does the profit for 2024 compare to 2023?",
    "What are the total assets and liabilities as of March 31, 2024?",
    "How much goodwill is recorded on the balance sheet?",
    "What is the net cash flow from operating activities?",
    "How does the cash flow from investing activities differ between 2023 and 2024?",
    "What were the significant financing activities in 2024?",
    "How much dividend was paid during the year?",
    "Were there any share buybacks or issuance of new shares?",
    "What does Note 2.1 state about business combinations?",
    "How are property, plant, and equipment (PPE) accounted for and valued according to Note 2.2?",
    "How much was spent on employee benefits?",
    "What is the carrying value of goodwill as of March 31, 2024?",
    "What are the critical accounting estimates and judgments described in the financial statements?",
    "How are property, plant, and equipment classified and accounted for?",
    "What are the details provided in Note 2.1 regarding business combinations?",
    "How is revenue from operations recognized in the financial statements?",
    "What is the basis of preparation for the interim condensed consolidated financial statements?",
    "What is the composition of investments under current and non-current assets?",
    "What is included in the condensed consolidated statement of changes in equity?",
    "What are the significant financial instruments described in Note 2.10?",
    "How are trade receivables presented in the financial statements?",
    "What are the components of cash and cash equivalents as per Note 2.8?",
    "What is the deferred tax liability or asset reported in the balance sheet?",
    "What are the provisions related to contingent liabilities and commitments in Note 2.21?",
    "How are leases accounted for in Note 2.19?",
    "What is the basis of consolidation mentioned in the overview section?",
    "How are related party transactions detailed in Note 2.22?",
    "What are the details of other income, net, provided in Note 2.17?",
    "What information is presented in the segment reporting section in Note 2.23?",
    "How is the income tax expense broken down in Note 2.15?"
]

import time

for query in queries:
    print(f"\nQuestion: {query}")
    answer = generate_response(query, index)
    print(f"Answer: {answer}")
    time.sleep(1)  #1-second delay between requests

import json
qa_pairs = []
for query in queries:
    print(f"\nQuestion: {query}")
    answer = generate_response(query, index)
    print(f"Answer: {answer}")
    qa_pairs.append({"question": query, "answer": answer})
    time.sleep(1)
output_file = "Tested_question_answers.json"
with open(output_file, "w") as f:
    json.dump(qa_pairs, f, indent=4)

print(f"\nQuestions and answers saved: {output_file}")